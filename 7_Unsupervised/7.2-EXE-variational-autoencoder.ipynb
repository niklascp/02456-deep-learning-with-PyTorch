{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "This is an exercise to be handed in on Peergrade\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display, clear_output\n",
    "import numpy as np\n",
    "%matplotlib nbagg\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(sns.dark_palette(\"purple\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Auto-encoders 101\n",
    "\n",
    "In this exercise we will implement a variational auto-encoder (VAE). An auto-encoder encodes some input into a new and usually more compact representation which can be used to reconstruct the input data again. A VAE makes the assumption that the compact representation follows a probabilistic distribution (usually Gaussian) which makes it possible to sample new points and decode them into new data from a trained variational auto-encoder. The \"variational\" part comes from the fact that these models are training through variational inference.\n",
    "\n",
    "The mathematical details of the training can be a bit challenging. However, we believe that probabilistic deep learning will be an important part of future machine learning, which is why we find it important to introduce the concepts.\n",
    "\n",
    "As background material we recommend reading [Tutorial on Variational Autoencoder](http://arxiv.org/abs/1606.05908). For the implementation of the model you can read the article \"Auto-Encoding Variational Bayes\", Kingma & Welling, ICLR 2014: http://arxiv.org/pdf/1312.6114v10.pdf and \"Stochastic Backpropagation and Approximate Inference in Deep Generative Models\", Rezende et al, ICML 2014: http://arxiv.org/pdf/1401.4082v3.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE crash course\n",
    "\n",
    "Like the simple auto-encoder, VAEs consist of two parts as seen in the figure below where all arrows are non-linear mappings through a neural network. The two parts are the:\n",
    "\n",
    " * **Encoder** (also known as recognition, inference or Q-model): Maps the input data into a probabilistic latent space, z, by defining the mean and variance parameters of a Gaussian distribution as non-linear functions of the input data x like:\n",
    "     - $q(z|x) = \\mathcal{N}(z|\\mu_\\theta(x), \\sigma_\\phi(x))$, which is called the approximate posterior or latent distribution. The parameters $\\mu_\\theta(x)$ (mean) and $\\log \\sigma_\\phi(x)^2$ (log-variance) are outputs from a hidden layer each.\n",
    " * **Decoder** (also known as generative, reconstruction or P-model): Conditioned on samples drawn from $z \\sim q(z|x)$ in the encoder the input data is reconstructed through the: \n",
    "     - $p(x|z)$, which is the conditional likelihood (generative distribution). The choice of the generative distribution depends on the nature of the features, so for binary pixel values an appropiate choice of reconstruction distribution is the [Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution), $p(x|z) = Ber(\\mu_\\phi(z)) = \\mu_\\phi(z)^x(1-\\mu_\\phi(z))^{1-k}$. $\\mu_\\phi(z)$ with $x=\\{0,1\\}$ is again the non-linear output of the last layer in the decoder. $\\mu_\\phi(z)$ is the probabilities of generating a 0 (black) or 1 (white) pixel value, like modelling 784 imbalanced coin-tossing processes. This is only possible because we assume the pixel intensities to be i.i.d. (Independent and Identically Distributed), so no direct correlations between them needs to modelled, even though we still achieve an indirect conditional correlation through the latent variables, z.\n",
    "     \n",
    "<img src=\"../static_files/VAE.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In more mathematical details we can get the marginal likelihood for the features, e.g. binary pixel values, by integrating out the latent variable in the joint distribution:\n",
    "\n",
    "$p(x) = \\int_z p(x,z) dz = \\int_z p(x|z)p(z)dz$\n",
    "\n",
    "As a trick to introduce the approximate posterior, $q(z|x)$, which is more feasible to compute compared to our unknown true posterior, $p(z|x)$, we can always multiply and divide by $q(z|x)$ and move them around without changing anything:\n",
    "\n",
    "$p(x) = \\int_z p(x|z)p(z)\\frac{q(z|x)}{q(z|x)}dz$\n",
    "\n",
    "\n",
    "$p(x) = \\int_z q(z|x) \\frac{p(x|z)p(z)}{q(z|x)}dz$\n",
    "\n",
    "Joint distributions can lead to underflow errors on a compute, so we instead try to maximize the log-likelihood  \n",
    "\n",
    "$\\log p(x) = \\log \\int_z q(z|x) \\frac{p(x|z)p(z)}{q(z|x)}dz = \\log \\mathbb{E}_{q(z|x)}\\left[\\frac{p(x|z)p(z)}{q(z|x)}\\right]$\n",
    "\n",
    "where we used that the integral is just the expectation (mean) wrt. $q(z|x)$ and in this case the $\\log$ can be moved inside the expectation by applying [Jensen's inequality](https://en.wikipedia.org/wiki/Jensen%27s_inequality):\n",
    "\n",
    "$\\log p(x) \\geq  \\int_z q(z|x)\\log \\frac{p(x|z)p(z)}{q(z|x)}dz =  \\mathbb{E}_{q(z|x)}\\left[\\log \\frac{p(x|z)p(z)}{q(z|x)}\\right] = \\mathcal{L}(x)$\n",
    "\n",
    "This, $\\mathcal{L}(x)$, is denoted the variational lower bound or evidence lower bound objective (ELBO). It is a lower bound to the log-likelihood and a tradeoff with the Kullback-Leibler divergence, $KL[q(z|x) || p(z|x)]$, between the approximate and true posterior, which we threw away when applying Jensen's inequality. This tradeoff is more easily understood through the derivation in the end of the notebook, so read it if you have the time. \n",
    "\n",
    "Like with Pokemons, there is a whole range of families of distributions to choose from, but we choose the most common one describing symmetric variations around a mean in signals with noise, the normal distribution:\n",
    "\n",
    "$q(z|x) = \\mathcal{N}(z|\\mu_\\theta(x), \\sigma_\\phi(x)I)$\n",
    "\n",
    "and a simple isotropic normal distribution as the latent prior\n",
    "\n",
    "$p(z) = \\mathcal{N}(z|0, I)$\n",
    "\n",
    "which becomes the part of the important regularising KL-term, when splitting up the lower bound as\n",
    "\n",
    "$\\mathcal{L}(x) = \\mathbb{E}_{q(z|x)} \\left[\\log p(x|z)\\right] - \\mathbb{E}_{q(z|x)}\\left[\\log \\frac{q(z|x)}{p(z)}\\right] = \\mathbb{E}_{q(z|x)} \\left[\\log p(x|z)\\right] - KL[q(z|x) || p(z)]$\n",
    "\n",
    "This is the function that we need to maximise, by minimising the negative lower bound. Here the first term on the R.H.S. is the data reconstruction and the second term the Kullback-Leibler divergence between the approximate and true posterior distributions which acts as a probabilistic regularizer forcing $q(z|x)$ to be close to having zero mean and identity variance, like $p(z)$. The KL-term can calculated analytically and the reconstruction error, $\\log p(x|z)$, is just the binary cross-entropy.\n",
    "\n",
    "### Training a VAE \n",
    "The VAE is similar to a deterministic autoencoder (1.Auto_Encoders) except that we assume that the latent units follows a distribution. Usually we just assume that the units are independent standard normally distributed (i.i.d.).\n",
    "\n",
    "Above we defined a lower bound on the log-likelihood of the data. We can train the model by maximising the lower bound w.r.t. the model parameters, weight matrices, through the stochastic gradient descent algorithm.  Feasible approximations of the expectations in the lower bound, $\\mathcal{L}(x)$, are obtained by evaluating the inside with samples drawn from the latent distribution, $z \\sim q(z|x) = \\mathcal{N}(z|\\mu_\\theta(x), \\sigma_\\phi(x)I)$ and dividing by the number of samples drawn. By using the _reparameterization trick_, $ \\mu_\\theta(x) + \\sigma_\\phi(x) \\cdot \\epsilon$, for the sampling procedure we can directly backpropogate gradients through the latent bottleneck and optimize the parameters w.r.t. the lower bound. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "First let us load the MNIST dataset and plot a few examples. We only load a limited amount of classes, controlled through the `classes` variable, to speed up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from functools import reduce\n",
    "\n",
    "# Flatten the images into a vector\n",
    "flatten = lambda x: ToTensor()(x).view(28**2)\n",
    "\n",
    "# Define the train and test sets\n",
    "dset_train = MNIST(\"./\", train=True,  transform=flatten, download=True)\n",
    "dset_test  = MNIST(\"./\", train=False, transform=flatten)\n",
    "\n",
    "# The digit classes to use\n",
    "classes = [3, 7]\n",
    "\n",
    "def stratified_sampler(labels):\n",
    "    \"\"\"Sampler that only picks datapoints corresponding to the specified classes\"\"\"\n",
    "    (indices,) = np.where(reduce(lambda x, y: x | y, [labels.numpy() == i for i in classes]))\n",
    "    indices = torch.from_numpy(indices)\n",
    "    return SubsetRandomSampler(indices)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "# The loaders perform the actual work\n",
    "train_loader = DataLoader(dset_train, batch_size=batch_size,\n",
    "                          sampler=stratified_sampler(dset_train.targets), pin_memory=cuda)\n",
    "test_loader  = DataLoader(dset_test, batch_size=batch_size, \n",
    "                          sampler=stratified_sampler(dset_test.targets), pin_memory=cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 64 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot a few MNIST examples\n",
    "f, axarr = plt.subplots(4, 16, figsize=(16, 4))\n",
    "\n",
    "# Load a batch of images into memory\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    ax.imshow(images[i].view(28, 28), cmap=\"binary_r\")\n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.suptitle('MNIST handwritten digits')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model\n",
    "When defining the model the latent layer must act as a bottleneck of information, so that we ensure that we find a strong internal representation. We initialize the VAE with 1 hidden layer in the encoder and decoder using relu units as non-linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VariationalAutoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=4, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=784, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.functional import softplus\n",
    "\n",
    "# define size variables\n",
    "num_features = 28**2\n",
    "\n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_features, num_samples):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        \n",
    "        self.latent_features = latent_features\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "        # We encode the data onto the latent space using two linear layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=num_features, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            # A Gaussian is fully characterised by its mean and variance\n",
    "            nn.Linear(in_features=128, out_features=2*self.latent_features) # <- note the 2*latent_features\n",
    "        )\n",
    "        \n",
    "        # The latent code must be decoded into the original image\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=self.latent_features, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=num_features)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x): \n",
    "        outputs = {}\n",
    "        \n",
    "        # Split encoder outputs into a mean and variance vector\n",
    "        mu, log_var = torch.chunk(self.encoder(x), 2, dim=-1)\n",
    "        \n",
    "        # Make sure that the log variance is positive\n",
    "        log_var = softplus(log_var)\n",
    "        \n",
    "        # :- Reparametrisation trick\n",
    "        # a sample from N(mu, sigma) is mu + sigma * epsilon\n",
    "        # where epsilon ~ N(0, 1)\n",
    "                \n",
    "        # Don't propagate gradients through randomness\n",
    "        with torch.no_grad():\n",
    "            batch_size = mu.size(0)\n",
    "            epsilon = torch.randn(batch_size, self.num_samples, self.latent_features)\n",
    "            \n",
    "            if cuda:\n",
    "                epsilon = epsilon.cuda()\n",
    "        \n",
    "        sigma = torch.exp(log_var/2)\n",
    "        \n",
    "        # We will need to unsqueeze to turn\n",
    "        # (batch_size, latent_dim) -> (batch_size, 1, latent_dim)\n",
    "        z = mu.unsqueeze(1) + epsilon * sigma.unsqueeze(1)        \n",
    "        \n",
    "        # Run through decoder\n",
    "        x = self.decoder(z)\n",
    "        \n",
    "        # The original digits are on the scale [0, 1]\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        # Mean over samples\n",
    "        x_hat = torch.mean(x, dim=1)\n",
    "        \n",
    "        outputs[\"x_hat\"] = x_hat\n",
    "        outputs[\"z\"] = z\n",
    "        outputs[\"mu\"] = mu\n",
    "        outputs[\"log_var\"] = log_var\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "\n",
    "latent_features = 2\n",
    "num_samples = 10\n",
    "\n",
    "net = VariationalAutoencoder(latent_features, num_samples)\n",
    "\n",
    "# Transfer model to GPU if available\n",
    "if cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following we define the PyTorch functions for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import binary_cross_entropy\n",
    "from torch import optim\n",
    "\n",
    "def ELBO_loss(y, t, mu, log_var):\n",
    "    # Reconstruction error, log[p(x|z)]\n",
    "    # Sum over features\n",
    "    likelihood = -binary_cross_entropy(y, t, reduction=\"none\")\n",
    "    likelihood = likelihood.view(likelihood.size(0), -1).sum(1)\n",
    "\n",
    "    # Regularization error: \n",
    "    # Kulback-Leibler divergence between approximate posterior, q(z|x)\n",
    "    # and prior p(z) = N(z | mu, sigma*I).\n",
    "    \n",
    "    # In the case of the KL-divergence between diagonal covariance Gaussian and \n",
    "    # a standard Gaussian, an analytic solution exists. Using this excerts a lower\n",
    "    # variance estimator of KL(q||p)\n",
    "    kl = -0.5 * torch.sum(1 + log_var - mu**2 - torch.exp(log_var), dim=1)\n",
    "\n",
    "    # Combining the two terms in the evidence lower bound objective (ELBO) \n",
    "    # mean over batch\n",
    "    ELBO = torch.mean(likelihood) - torch.mean(kl)\n",
    "    \n",
    "    # notice minus sign as we want to maximise ELBO\n",
    "    return -ELBO, kl.sum()\n",
    "\n",
    "\n",
    "# define our optimizer\n",
    "# The Adam optimizer works really well with VAEs.\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_function = ELBO_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the forward pass, to check that everything is in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-92d805b38b75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mx_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x_hat\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter/env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-13a7449986c0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Split encoder outputs into a mean and variance vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Make sure that the log variance is positive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter/env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter/env/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter/env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter/env/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter/env/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "x, _ = next(iter(train_loader))\n",
    "x = Variable(x)\n",
    "\n",
    "if cuda:\n",
    "    x = x.cuda()\n",
    "\n",
    "outputs = net(x)\n",
    "\n",
    "x_hat = outputs[\"x_hat\"]\n",
    "mu, log_var = outputs[\"mu\"], outputs[\"log_var\"]\n",
    "z = outputs[\"z\"]\n",
    "\n",
    "loss, kl = loss_function(x_hat, x, mu, log_var)\n",
    "\n",
    "print(x.shape)\n",
    "print(x_hat.shape)\n",
    "print(z.shape)\n",
    "print(loss)\n",
    "print(kl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the training loop we sample each batch and evaluate the error, latent space, and reconstructions on every epoch.\n",
    "\n",
    "**NOTE** this will take a while on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "num_epochs = 100\n",
    "tmp_img = \"tmp_vae_out.png\"\n",
    "show_sampling_points = False\n",
    "\n",
    "train_loss, valid_loss = [], []\n",
    "train_kl, valid_kl = [], []\n",
    "\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    batch_loss, batch_kl = [], []\n",
    "    net.train()\n",
    "    \n",
    "    # Go through each batch in the training dataset using the loader\n",
    "    # Note that y is not necessarily known as it is here\n",
    "    for x, y in train_loader:\n",
    "        x = Variable(x)\n",
    "        \n",
    "        # This is an alternative way of putting\n",
    "        # a tensor on the GPU\n",
    "        x = x.to(device)\n",
    "        \n",
    "        outputs = net(x)\n",
    "        x_hat = outputs['x_hat']\n",
    "        mu, log_var = outputs['mu'], outputs['log_var']\n",
    "\n",
    "        elbo, kl = loss_function(x_hat, x, mu, log_var)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        elbo.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss.append(elbo.item())\n",
    "        batch_kl.append(kl.item())\n",
    "\n",
    "    train_loss.append(np.mean(batch_loss))\n",
    "    train_kl.append(np.mean(batch_kl))\n",
    "\n",
    "    # Evaluate, do not propagate gradients\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        \n",
    "        # Just load a single batch from the test loader\n",
    "        x, y = next(iter(test_loader))\n",
    "        x = Variable(x)\n",
    "        \n",
    "        x = x.to(device)\n",
    "        \n",
    "        outputs = net(x)\n",
    "        x_hat = outputs['x_hat']\n",
    "        mu, log_var = outputs['mu'], outputs['log_var']\n",
    "        z = outputs[\"z\"]\n",
    "\n",
    "        elbo, kl = loss_function(x_hat, x, mu, log_var)\n",
    "        \n",
    "        # We save the latent variable and reconstruction for later use\n",
    "        # we will need them on the CPU to plot\n",
    "        x = x.to(\"cpu\")\n",
    "        x_hat = x_hat.to(\"cpu\")\n",
    "        z = z.detach().to(\"cpu\").numpy()\n",
    "\n",
    "        valid_loss.append(elbo.item())\n",
    "        valid_kl.append(kl.item())\n",
    "    \n",
    "    if epoch == 0:\n",
    "        continue\n",
    "    \n",
    "    # -- Plotting --\n",
    "    f, axarr = plt.subplots(3, 2, figsize=(20, 20))\n",
    "\n",
    "    # Loss\n",
    "    ax = axarr[0, 0]\n",
    "    ax.set_title(\"ELBO\")\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Error')\n",
    "\n",
    "    ax.plot(np.arange(epoch+1), train_loss, color=\"black\")\n",
    "    ax.plot(np.arange(epoch+1), valid_loss, color=\"gray\", linestyle=\"--\")\n",
    "    ax.legend(['Training', 'Validation'])\n",
    "\n",
    "    # Latent space\n",
    "    ax = axarr[0, 1]\n",
    "\n",
    "    ax.set_title('Latent space')\n",
    "    ax.set_xlabel('Dimension 1')\n",
    "    ax.set_ylabel('Dimension 2')\n",
    "    \n",
    "    rows = 8\n",
    "    columns = batch_size // rows\n",
    "    \n",
    "    span = np.linspace(-4, 4, rows)\n",
    "    grid = np.dstack(np.meshgrid(span, span)).reshape(-1, 2)\n",
    "    \n",
    "    # If you want to use a dimensionality reduction method you can use\n",
    "    # for example PCA by projecting on two principal dimensions\n",
    "    # z = PCA(n=2).fit_transform(z)\n",
    "\n",
    "    colors = iter(plt.get_cmap('Set1')(np.linspace(0, 1.0, len(classes))))\n",
    "    for c in classes:\n",
    "        ax.scatter(*z[c == y.numpy()].reshape(-1, 2).T, c=next(colors), marker='o', label=c)\n",
    "        \n",
    "    if show_sampling_points:\n",
    "        ax.scatter(*grid.T, color=\"k\", marker=\"x\", alpha=0.5, label=\"Sampling points\")\n",
    "\n",
    "    ax.legend()\n",
    "    \n",
    "    # KL / reconstruction\n",
    "    ax = axarr[1, 0]\n",
    "    \n",
    "    ax.set_title(\"Kullback-Leibler Divergence\")\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('KL divergence')\n",
    "\n",
    "\n",
    "    ax.plot(np.arange(epoch+1), train_kl, color=\"black\")\n",
    "    ax.plot(np.arange(epoch+1), valid_kl, color=\"gray\", linestyle=\"--\")\n",
    "    ax.legend(['Training', 'Validation'])\n",
    "    \n",
    "    # Latent space samples\n",
    "    ax = axarr[1, 1]\n",
    "    ax.set_title('Samples from latent space')\n",
    "    ax.axis('off')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        epsilon = torch.from_numpy(grid).float().to(device)\n",
    "        samples = torch.sigmoid(net.decoder(epsilon)).detach()\n",
    "\n",
    "    canvas = np.zeros((28*rows, columns*28))\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            idx = i % columns + rows * j\n",
    "            canvas[i*28:(i+1)*28, j*28:(j+1)*28] = samples[idx].reshape((28, 28))\n",
    "    ax.imshow(canvas, cmap='gray')\n",
    "\n",
    "    # Inputs\n",
    "    ax = axarr[2, 0]\n",
    "    ax.set_title('Inputs')\n",
    "    ax.axis('off')\n",
    "\n",
    "    canvas = np.zeros((28*rows, columns*28))\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            idx = i % columns + rows * j\n",
    "            canvas[i*28:(i+1)*28, j*28:(j+1)*28] = x[idx].reshape((28, 28))\n",
    "    ax.imshow(canvas, cmap='gray')\n",
    "\n",
    "    # Reconstructions\n",
    "    ax = axarr[2, 1]\n",
    "    ax.set_title('Reconstructions')\n",
    "    ax.axis('off')\n",
    "\n",
    "    canvas = np.zeros((28*rows, columns*28))\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            idx = i % columns + rows * j\n",
    "            canvas[i*28:(i+1)*28, j*28:(j+1)*28] = x_hat[idx].reshape((28, 28))\n",
    "    ax.imshow(canvas, cmap='gray')\n",
    "    \n",
    "    plt.savefig(tmp_img)\n",
    "    plt.close(f)\n",
    "    display(Image(filename=tmp_img))\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    os.remove(tmp_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the VAE\n",
    "\n",
    "## Mandatory Exercises\n",
    "\n",
    "- Experiment with the number of layers and activation functions in order to improve the reconstructions and latent representation. What solution did you find the best and why?\n",
    "- Try to increase the number of digit classes in the training set and analyze the learning curves, latent space and reconstructions. For which classes and why does the VAE fail in reconstructing?  *HINT: Try the combination: `classes=[0, 1, 4, 9]`, to see how well VAE can separate these digits in the latent representation and reconstructions.*\n",
    "- Increase the number of units in the latent layer. Does it increase the models representational power and how can you see and explain this? How does this affect the quality of the reconstructions? *HINT: You can visualize the latent space in 2D by transforming z to a lower dimensional representation with [PCA](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) or [t-SNE](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)*\n",
    "\n",
    "**Answers**:\n",
    "\n",
    "### 2. Analyze the purpose of the KL-term\n",
    "\n",
    "- How does the KL-term, $KL[q(z|x)||p(z)]$, work as a regulariser on the distributions over latent variables? *HINT*: When maximising the ELBO, the probability-distance measure is minimised $KL[q(z|x)||p(z)] \\rightarrow 0$ so that $q(z|x) \\rightarrow p(z) = \\mathcal{N}(z|0,I)$ for all examples, x. At $KL[q(z|x)||p(z)] = 0$ variations in x stops having an affect on the latent distribution and latent units are all described by the same distribution, $\\mathcal{N}(z|0,I)$, so they produce a noisy output without signal $z=\\epsilon$ to the decoder.\n",
    "- Try removing the KL-term ($KL \\cdot 0$ in `ELBO_loss`) and analyze what happens during training, in the learning curves, latent representation and reconstructions compared to before removing it.\n",
    "- Notice what the loss reduces to and explain how this can affect a VAE. *HINT*: Compare loss function for AE and VAE, and remember that we can use the pixel-wise binary crossentropy error as the loss in the AEs and for the reconstruction error, $\\log p(x|z) = \\log Ber(\\mu_\\phi(z))$, in VAEs.\n",
    "\n",
    "**Answers**:\n",
    "\n",
    "### 3. Sampling in the VAE\n",
    "\n",
    "- Explain how one could implement multiple samples in the VAE and how that would improve learning. *HINT*: Look into how the samples are drawn in the definition of the `VariationalAutoencoder` class.\n",
    "- Experiment with `num_samples` used when initialising the VAE. Does it improve the reconstructions and how/why?\n",
    "\n",
    "**Answers**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional exercises\n",
    "\n",
    "- OPT: Use the original paper http://arxiv.org/pdf/1312.6114v10.pdf or [this blog](http://blog.shakirm.com/2015/10/machine-learning-trick-of-the-day-4-reparameterisation-tricks/) to explain what the reparameterization trick does.\n",
    "- OPT: Look through https://arxiv.org/abs/1611.00712 or https://arxiv.org/abs/1611.01144 and explain how one could instead introduce a categorical latent variable for $z$.\n",
    "- OPT: Implement the Gumbel softmax trick thereby letting $z$ take a categorical distribution.\n",
    "- OPT: The VAE is a probablistic model. We could model $p(x,z,y)$ where $y$ is the label information. Explain how this model could handle semi-supervised learning? You can look through the papers https://arxiv.org/pdf/1406.5298.pdf or  https://arxiv.org/pdf/1602.05473v4.pdf or again the two papers on Gumbel softmax.\n",
    "\n",
    "**Answers**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The tradeoff connection between the lower bound and KL-divergence\n",
    "To understand this tradeoff connection, we flip the whole problem around into the perspective of the KL-divergence\n",
    "\n",
    "$KL[q(z|x) || p(z|x)] = \\int_z q(z|x)\\log \\frac{q(z|x)}{p(z|x)}dz = \\mathbb{E}_{q(z|x)}\\left[\\log \\frac{q(z|x)}{p(z|x)}\\right]$,\n",
    "\n",
    "which is a non-negative distance measure between distributions, so by minimising it wrt. to the parameters in $q(z|x)$, the distribution moves close to our unknown $p(z|x)$. But as $p(z|x)$ is unknown and would include some rather intractable integrals over neural networks, we can instead get rid of it by expressing it through Bayes rule $p(z|x) = p(x|z)p(z)/p(x)$ and thereby decompose the KL-divergence into our log-likelihood and lower bound:\n",
    "\n",
    "$ KL[q(z|x) || p(z|x)] = \\int_z q(z|x)\\log \\frac{q(z|x)p(x)}{p(x|z)p(z)}dz = \\int_z q(z|x)\\log \\frac{q(z|x)}{p(x|z)p(z)}dz + \\log p(x)$ \n",
    "\n",
    "by seeing that the likelihood, $p(x)$, is independent of $z$ and pull it out of the integral. We can flip the sign and fraction in the integral term to recognise it as the negative lower bound\n",
    "\n",
    "$KL[q(z|x) || p(z|x)] = - \\int_z q(z|x)\\log \\frac{p(x|z)p(z)}{q(z|x)}dz + \\log p(x) =  -\\mathcal{L}(x) + \\log p(x)$\n",
    "\n",
    "We then find the log-likelihood to consist of the two terms and hold the inequality\n",
    "\n",
    "$\\log p(x) =  KL[q(z|x) || p(z|x)] + \\mathcal{L}(x) \\geq \\mathcal{L}(x)$\n",
    "\n",
    "where the KL-divergence is non-zero and the log-likelihood is $\\log p(x) \\leq 0$. This means that maximising the lower bound from the negative domain towards $0$ will also maximise the log-likelihood, while pushing down the KL-divergence until $q(z|x)$ cannot move closer to natures true distribution, $p(z|x)$. So how close the lower bound can get to the log-likelihood is dependent on the flexibility of the distribution we choose for $q(z|x)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Michael Nielsen book exercise of own choice\n",
    "Pick an exercise of own choice from Michael Nielsens book\n",
    "    \n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits \n",
    "\n",
    "> Original [Theano/Lasagne tutorial](https://github.com/DeepLearningDTU/nvidia_deep_learning_summercamp_2016/blob/master/lab1/lab1_FFN.ipynb) by \n",
    "Lars Maaløe ([larsmaaloee](https://github.com/larsmaaloee)),\n",
    "Søren Kaae Sønderby ([skaae](https://github.com/skaae)), and \n",
    "Casper Sønderby ([casperkaae](https://github.com/casperkaae)). \n",
    "Converted to TensorFlow and updated by \n",
    "Maximillian F. Vording ([maximillian91](https://github.com/maximillian91)).\n",
    "Converted to PyTorch and updated by Jesper Wohlert ([wohlert](https://github.com/wohlert))."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
